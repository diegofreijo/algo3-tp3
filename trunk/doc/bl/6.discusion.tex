\subsection{Discusi'on}
En el primer gr'afico se pueden apreciar que los porcentajes s'olo llegan hasta el 40\%. 'Esta fue una decisi'on tomada por el grupo para acotar los tiempos de procesamiento. Pero no fue tomada al azar. Como se puede ver, a media que ambos par'ametros aumentan, el puntaje disminuye dr'asticamente. En las primeras pruebas realizadas se utilizaba la totalidad de los porcentajes, pero el resultado era el mismo: la superficie se achataba a medida que crec'ian, por lo que no se quit'o informaci'on al obviarlos. 

'Esta acumulaci'on de la importancia cerca de los par'ametros peque'nos fue inesperada. El grupo crey'o que con valores peque'nos funcionar'ia mejor el algoritmo, pero no tan cercanos al 0. En cierta parte es esperable ya que al quitar o agregar demasiada cantidad de nodos, el algoritmo pierde cierta \emph{flexibilidad} para generar soluciones, especialmente peque'nas.

Los mejores par'ametros fueron\footnote{Para mayor informaci'on sobre los mejores puntajes, dirigirse al ap'endice correspondiente.}: (0,1), (0,2) y (1,2), ley'endose 'estas tuplas como (porcentaje cuantos agrego, porcentaje cuantos saco). Preferimos tomar al menor de ellos como el mejor, y la decisi'on se bas'o principalmente en la ya mencionada acumulaci'on de puntajes cerca del (0,0) (es decir, al parecer los valores mas peque'nos son los que mejor funcionan). Por ende, el (0,1) es nuestro mejor par.

En el segundo y tercer gr'afico ya utilizamos el par'ametro calculado anteriormente para averiguar la cantidad de instrucciones que cuesta cada ejecuci'on. 

El primero de los dos utiliza grafos todos con la misma cantidad de nodos pero densidad (porcentaje de la cantidad total de posibles ejes) variable. Notar que $m$ fue dividido por la cantidad m'axima de ejes posibles $\left(\frac{n(n-1)}{2}\right)$ siendo en 'este caso $n=40$) del grafo para obtener la densidad y as'i ser posible plasmar los valores en un gr'afico que se encuentra en funci'on de la densidad. El asombro del grupo aqu'i fue en la gran constante por la que se tuvo que multiplicar a la complejidad te'orica para obtener la ajustada. Creemos que 'esto pudo darse, principalmente, por la acotaci'on que se realiz'o en la complejidad en MejorVecino. Como muchas constantes fueron eliminadas, 'esto pudo influir en que la complejidad resultante necesite ser multiplicada por una grande para recuperar las acotaciones. Lo m'as importante es que a pesar de todo la cota es v'alida\footnote{Notar que el gr'afico est'a completo ya que abarca del 0 al 100 porciento en la densidad. Es decir, el asegurarse que aqu'i la cota se consigui'o asegura que es v'alida para el gr'afico.} porque se pudo obtener 'esta constante para ajustar.

El segundo de los gr'aficos de instrucciones fija la densidad de los grafos (50\%) y var'ia la cantidad de nodos. La curva te'orica dibujada se baso en que $m$ sea el mayor valor posible en el grafo (es decir, cuando la cantidad de nodos es m'axima: $50*49/2 \approx 600$) y es por eso que nos pareci'o, en principio, tan exagerada la cota. Por otro lado, la complejidad te'orica est'a basada en casos que son pr'acticamente imposibles en la realidad. Por ejemplo, las $n$ llamadas a MejorVecino explicado en la complejidad del algoritmo principal, BusquedaLocal (entre otros). Igualmente no nos preocupa porque en el peor caso es verdad que puede llegar a suceder, asique no se la puede considerar una "mala cota".

Los dos 'ultimos gr'aficos intentan mostrar la bondad de las soluciones de la b'usqueda local, bas'andonos nuevamente en el mejor par obtenido anteriormente. La primer comparaci'on nos pareci'o que arroj'o resultados favorables ya que, en promedio, la mayor diferencia en el recubrimiento es de uno o nung'un nodo. Notar que a medida que aumenta la densidad del grafo, los errores disminuyen. Sin embargo, en el que realiza comparaciones en funci'on de la cantidad de nodos no se encuentra patr'on alguno (por lo menos para la cantidad de muestras que pudimos computar). 'Esto nos parece extra'no pero la 'unica explicaci'on disponible es que trabajamos con grafos aleatorios, y si quisi'esemos encontrar detalles a 'este nivel deber'iamos analizar grafo por grafo.
